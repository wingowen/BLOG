{"meta":{"title":"WINGO'S BLOG","subtitle":"","description":"","author":"Wingo Wen","url":"https://wingowen.github.io","root":"/"},"pages":[{"title":"分类","date":"2022-07-29T10:17:24.000Z","updated":"2022-07-29T10:18:07.390Z","comments":true,"path":"categories/index.html","permalink":"https://wingowen.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-07-29T10:18:35.000Z","updated":"2022-07-29T10:18:54.011Z","comments":true,"path":"tags/index.html","permalink":"https://wingowen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"模型评估与选择","slug":"模型评估与选择","date":"2022-07-29T10:24:58.000Z","updated":"2022-07-29T23:58:50.538Z","comments":true,"path":"2022/07/29/模型评估与选择/","link":"","permalink":"https://wingowen.github.io/2022/07/29/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/","excerpt":"","text":"错误率和精度123456789101112131415161718import numpy as np# 真实的数据标签real_label = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1]) \\ \\ \\# 分类器的预测标签classifier_pred = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])compare_result = (real_label == classifier_pred)compare_result = compare_result.astype(np.int)# m 为样本数量 b 为预测错误样本m = len(real)b = m - np.sum(cmp)# 错误率error_rate = (b / m)*100# 精确度 accaccuracy = (1 - b / m)*100 误差模型在训练样本上的误差称为训练误差或经验误差；模型在新样本上的误差称为泛化误差。 过拟合模型：虽然训练误差接近 0，泛化误差非常大。 欠拟合的模型无论是在训练集中还是在新样本上，表现都很差，即经验误差和泛化误差都很大。 偏差和方差偏差-方差分解 bias-variance decomposition， 是解释学习算法泛化性能的一种重要工具。 偏差 bias，与真实值的偏离程度； 方差 variance，该随机变量在其期望值附近的波动程度。 评估方法评估：对学习器的泛化误差进行评估并进而做出选择。 留出法以一定比例划分训练集和测试集。 1234567891011121314151617181920212223# 导入包import numpy as npfrom sklearn.model_selection import train_test_split# 加载数据集def load_pts(): &#x27;&#x27;&#x27; return: 返回随机生成 200 个点的坐标 &#x27;&#x27;&#x27; dots = 200 # 样本数 dim = 2 # 数据维度 X = np.random.randn(dots,dim) # 建立数据集，shape(200,2) # 建立样本 X 的类别 Y = np.zeros(dots, dtype=&#x27;int&#x27;) for i in range(X.shape[0]): Y[i] = 1 return X, Y# 加载数据X,Y = load_pts()# 使用train_test_split划分训练集和测试集train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=0) 交叉验证交叉验证法 cross validation，先将数据集 D 划分为 k 个大小相似的互斥子集。 12345678910111213# 导入包from sklearn.model_selection import KFoldimport numpy as np# 生成数据集，随机生成40个点data = np.random.randn(40,2)# 交叉验证法kf = KFold(n_splits = 4, shuffle = False, random_state = None) for train, test in kf.split(data): print(train) print(test,&#x27;\\n&#x27;) 自助法有放回抽样，给定包含 m 个样本的数据集 D，我们对它进行采样产生数据集 D’ ： 每次随机从 D 中挑选一个样本； 将该样本拷贝放入 D’，然后再将该样本放回初始数据集 D 中； 重复执行 m 次该过程； 最后得到包含 m 个样本数据集 D’。 由上述表达式可知，初始数据集与自助采样数据集 D1’，自助采样数据集 D2’ 的概率分布不一样，且自助法采样的数据集正负类别比例与原始数据集不同。因此用自助法采样的数据集代替初始数据集来构建模型存在估计偏差。 123456789101112131415161718# 导入包import numpy as np# 任意设置一个数据集X = [1,4,3,23,4,6,7,8,9,45,67,89,34,54,76,98,43,52]# 通过产生的随机数获得抽取样本的序号 bootstrapping = []for i in range(len(X)): bootstrapping.append(np.random.randint(0,len(X),(1)))# 通过序号获得原始数据集中的数据D_1 = []for i in range(len(X)): print(int(bootstrapping[i])) D_1.append(X[int(bootstrapping[i])]) print(D_1) 总结 采样方法 与原始数据集的分布是否相同 相比原始数据集的容量 是否适用小数据集 是否适用大数据集 是否存在估计偏差 留出法 分层抽样 否 变小 否 是 是 交叉验证法 分层抽样 否 变小 否 是 是 自助法 放回抽样 否 不变 是 否 是 性能度量性能度量：对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量。 性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。这意味着模型的好坏是相对的，什么样的模型是好的? 这不仅取决于算法和数据，还决定于任务需求。 回归任务常用性能度量：MSE mean square error，均方差。 分类任务常用性能度量：acc accuracy，精度；错误率 二分类 - 查准率、查全率、F1对于二分类问题，可将样例根据真实值与学习器预测类别组合划分为： 真正例 true positive 假正例 false positive 真反例 true negative 假反例 false negative P(\\text { Precision })=\\frac{T P}{T P+F P} \\\\R(\\text { Recall })=\\frac{T P}{T P+F N}Recall，查全率、召回率：计算实际为正的样本中，预测正确的样本比例。 Precision，查准率：在预测为正的样本中，实际为正的概率。 P-R 曲线，BRP，Break Even Point：平衡单 P = R。 由 P-R 曲线可以看出，查全率与准确率是成反比的，这里可以理解为为了获取所有正样本而牺牲了准确性，即广撒网。BRP 还是过于简单，更常用的是 F1 度量。 F 1=\\frac{2 \\times P \\times R}{P+R}=\\frac{2 T P}{n+T P-T N}F1 的核心思想在于，在尽可能的提高 P 和 R 的同时，也希望两者之间的差异尽可能小。 当对 P 和 R 有所偏向时，则需要 F1 更泛性的度 Fβ。 F_{\\beta}=\\frac{\\left(1+\\beta^{2}\\right) \\times P \\times R}{\\left(\\beta^{2} \\times P\\right)+R}β &gt; 1时更偏向 R，β &lt; 1 更偏向 P。 如果使用了类似交叉验证法，我们会得到多个 confusion matrix： 宏观 macroF1 对于每个 confusion matrix 先计算出P、R，然后求得平均并带入公式求 macroF1； 微观 microF1 先求 confusion matrix 各元素的平均值，然后计算 P、R。 123456789101112131415161718192021222324252627282930313233343536373839404142434445import numpy as np# 加载数据集def generate_data(random_state=2021): &quot;&quot;&quot; :返回值: GT_label: 数据集的真实标签，0表示非苹果，1表示苹果 Pred_Score: 模型对数据样本预测为苹果的分数，取值范围为[0,1] &quot;&quot;&quot; noise_rate = 0.1 # 噪声比例 sample_num = 4096 # 总样本数 noise_sample_num = int(sample_num*noise_rate) # 噪声样本数 np.random.seed(random_state) Pred_Score = np.random.uniform(0,1,sample_num) GT_label = (Pred_Score&gt;0.5).astype(np.int) noise_ids = np.random.choice(a=sample_num, size=noise_sample_num, replace=False, p=None) for index in noise_ids: GT_label[index] = 1 if GT_label[index] == 0 else 0 return GT_label, Pred_ScoreGT_label, Pred_Score = generate_data()# 请你补全以下代码，计算查准率与查全率def get_PR(GT_label, Pred_Score, threshold, random_state=2021): &quot;&quot;&quot; 计算错误率和精度 :GT_label: 数据集的真实标签，0表示非苹果，1表示苹果 :Pred_Score: 模型对数据样本预测为苹果的分数，取值范围为[0,1] :threshold: 评估阈值 :random_state: 随机种子 :返回值: P: 查准率 R: 查全率 &quot;&quot;&quot; Pred_Label = list(map(lambda x: 1 if x &gt; threshold else 0, Pred_Score)) from sklearn.metrics import precision_score, recall_score P = precision_score(GT_label, Pred_Label) R = recall_score(GT_label, Pred_Label) &quot;&quot;&quot; TODO &quot;&quot;&quot; return P, R P, R = get_PR(GT_label, Pred_Score, 0.55, random_state=2021)print(&quot;查准率P ：&#123;:.2f&#125;&quot;.format(P))print(&quot;查全率R ：&#123;:.2f&#125;&quot;.format(R)) ROC 与 AUC 原理ROC 全称是受试者工作特征 Receiver Operating Characteristic) 。与 P-R 曲线不同的是，ROC使用了真正例率和假正例率。 \\begin{aligned}T P R(\\text { Precision }) &=\\frac{T P}{T P+F N} \\\\F P R(\\text { Precision }) &=\\frac{F P}{F P+T N}\\end{aligned}TPR 真正率，真正样本与实际为正的样本的比率； FPR 假正率，加正样本与实际为负的样本的比率。 若一个学习器的 ROC 曲线被另一个学习器的曲线完全包住，则可断言后者的性能优于前者； 若两 个学习器的 ROC 曲线发生交叉，则难以一般性地断言两者孰优孰劣。此时如果一定要进行比较，则较为合理的判据是比较 ROC 曲线下的面积，即 AUC Area Under ROC Curve。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import numpy as npimport matplotlib.pyplot as pltfrom sklearn.model_selection import train_test_split# 加载数据集def load_pts(): dots = 200 # 点数 X = np.random.randn(dots,2) * 15 # 建立数据集，shape(200,2)，坐标放大15倍 # 建立 X 的类别 y = np.zeros(dots, dtype=&#x27;int&#x27;) for i in range(X.shape[0]): if X[i,0] &gt; -15 and X[i,0] &lt; 15 and X[i,1] &gt; -15 and X[i,1] &lt; 15: # 矩形框内的样本都是目标类（正例） y[i] = 1 if 0 == np.random.randint(i+1) % 10: # 对数据随机地插入错误，20 个左右 y[i] = 1 - y[i] # 数据集可视化 plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 20, color = &#x27;blue&#x27;, edgecolor = &#x27;k&#x27;) plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 20, color = &#x27;red&#x27;, edgecolor = &#x27;k&#x27;) plt.xlim(-40,40) plt.ylim(-40,40) plt.grid(False) plt.tick_params( axis=&#x27;x&#x27;, which=&#x27;both&#x27;, bottom=False, top=False) return X, yX, y = load_pts()plt.show()### 训练模型 ###from sklearn.model_selection import train_test_splitfrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.svm import SVC# 将数据集拆分成训练集和测试集X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2) # 建立模型 clf1 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=4,min_samples_split=4)clf2 = GradientBoostingClassifier(max_depth=8, min_samples_leaf=10, min_samples_split=10)clf3 = SVC(kernel=&#x27;rbf&#x27;, gamma=0.001, probability=True)# 训练模型clf1.fit(X_train, y_train)clf2.fit(X_train, y_train)clf3.fit(X_train, y_train)### 评估模型 ###from sklearn.metrics import roc_curve# 模型预测y_score1 = clf1.predict_proba(X_test)y_score2 = clf2.predict_proba(X_test)y_score3 = clf3.predict_proba(X_test)# 获得 FPR、TPR 值fpr1, tpr1, _ = roc_curve(y_test, y_score1[:,1])fpr2, tpr2, _ = roc_curve(y_test, y_score2[:,1])fpr3, tpr3, _ = roc_curve(y_test, y_score3[:,1])### 绘制 ROC 曲线 ###from sklearn.metrics import aucplt.figure()# 绘制 ROC 函数def plot_roc_curve(fpr, tpr, c, name): lw = 2 roc_auc = auc(fpr,tpr) plt.plot(fpr, tpr, color=c,lw=lw, label= name +&#x27; (area = %0.2f)&#x27; % roc_auc) plt.plot([0,1], [0,1], color=&#x27;navy&#x27;, lw=lw, linestyle=&#x27;--&#x27;) plt.xlim([0, 1.0]) plt.ylim([0, 1.05]) plt.xlabel(&#x27;False Positive Rate&#x27;) plt.ylabel(&#x27;True Positive Rate&#x27;) #plt.title(&#x27;&#x27;) plt.legend(loc=&quot;lower right&quot;) plot_roc_curve(fpr1, tpr1, &#x27;red&#x27;,&#x27;DecisionTreeClassifier &#x27;) plot_roc_curve(fpr2, tpr2, &#x27;navy&#x27;,&#x27;GradientBoostingClassifier &#x27;) plot_roc_curve(fpr3, tpr3, &#x27;green&#x27;,&#x27;SVC &#x27;) plt.show() 比较检验（TODO）模型性能比较的重要因素： 实验评估得到的性能不等于泛化性能； 测试集上的性能与测试集本身的选择有很大关系； 很多机器学习算法本身有一定的随机性。 统计假设检验为我们进行学习器性能比较提供了重要依据。基于假设检验结果我们可推断出：哪个学习器更优秀，并且成立的把我有多大。 假设检验由样本推测总体的方法。 交叉验证 t 检验McNemar 检验Friedman 检验与 Nemenyi 后续检验类别不平衡在分类任务中，当不同类别的训练样本数量差别很大时，训练得到的模型往往泛化性很差 ，这就是类别不平衡。如在风控系统识别中，欺诈的样本应该是很少部分。 如果类别不平衡比例超过 4:1，那么其分类器会大大地因为数据不平衡性而无法满足分类要求的。 解决不平衡分类问题的策略可以分为两大类： 从数据层面入手 , 通过改变训练集样本分布降低不平衡程度； 从算法层面入手 , 根据算法在解决不平衡问题时的缺陷，适当地修改算法使之适应不平衡分类问题。 数据层面解决类别不平衡扩大数据样本。 重采样：通过过增加稀有类训练样本数的过采样和减少大类样本数的欠采样使不平衡的样本分布变得比较平衡 ，从而提高分类器对稀有类的识别率。 过采样：复制稀有样本； 123456789101112131415161718192021222324252627282930313233# 导入包from sklearn.datasets import make_classificationfrom collections import Counterfrom imblearn.over_sampling import RandomOverSampler# 生成样本集，用于分类算法：3 类，5000 个样本，特征维度为 2X, y = make_classification(n_samples=5000, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_classes=3, n_clusters_per_class=1, weights=[0.01, 0.05, 0.94], class_sep=0.8, random_state=0)# 打印每个类别样本数print(Counter(y))# 过采样ros = RandomOverSampler(random_state=0)X_resampled, y_resampled = ros.fit_resample(X, y)# 打印过采样后每个类别样本数print(sorted(Counter(y_resampled).items()))# 生成新的稀有样本# 导入包from imblearn.over_sampling import SMOTE# 过采样sm = SMOTE(random_state=42)X_res, y_res = sm.fit_resample(X, y)# 打印过采样后每个类别样本数print(&#x27;Resampled dataset shape %s&#x27; % Counter(y_res)) 欠采样：保存所有稀有类样本，并在丰富类别中随机选择与稀有类别样本相等数量的样本。 123456789# 导入包from imblearn.under_sampling import RandomUnderSampler# 欠采样rus = RandomUnderSampler(random_state=0)X_resampled, y_resampled = rus.fit_resample(X, y)# 打印欠采样后每个类别样本数print(sorted(Counter(y_resampled).items())) 过采样与欠采样结合：在之前的SMOTE方法中, 生成无重复的新的稀有类样本, 也很容易生成一些噪音数据。 因此, 在过采样之后需要对样本进行清洗。常见的有两种方法：SMOTETomek、SMOTEENN。 12345678# 导入包from imblearn.combine import SMOTEENN# 过采样与欠采样结合smote_enn = SMOTEENN(random_state=0)X_resampled, y_resampled = smote_enn.fit_resample(X, y)# 打印采样后每个类别样本数print(sorted(Counter(y_resampled).items())) 算法层面解决类别不平衡惩罚项方法：在大部分不平衡分类问题中，稀有类是分类的重点，在这种情况下正确识别出稀有类的样本比识别大类的样本更有价值，反过来说，错分稀有类的样本需要付出更大的代价。 通过设计一个代价函数来惩罚稀有类别的错误分类而不是分类丰富类别，可以设计出许多自然泛化为稀有类别的模型。 例如，调整 SVM 以惩罚稀有类别的错误分类。 1234567# LABEL 0 4000# LABEL 1 200# 导入相关包from sklearn.svm import SVC# 添加惩罚项clf = SVC(C=0.8, probability=True, class_weight=&#123;0:0.25, 1:0.75&#125;) 特征选择方法 样本数量分布很不平衡时，特征的分布同样也会不平衡。 大类中经常出现的特征也许在稀有类中根本不出现，这样的特征是冗余的。 选取最具有区分能力的特征，有利于提高稀有类的识别率。特征选择比较不错的方法是决策树，如 C4.5、C5.0、CART 和随机森林。","categories":[{"name":"算法","slug":"算法","permalink":"https://wingowen.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://wingowen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"贝叶斯算法","slug":"贝叶斯算法","date":"2022-07-29T10:24:58.000Z","updated":"2022-07-29T10:33:34.976Z","comments":true,"path":"2022/07/29/贝叶斯算法/","link":"","permalink":"https://wingowen.github.io/2022/07/29/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/","excerpt":"","text":"条件概率P(A|B) 表示事件 B 发生的前提下，事件 A 发生的概率： P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)}P(B|A) 表示事件 A 发生的前提下，事件 B 发生的概率： P(B \\mid A)=\\frac{P(A \\cap B)}{P(A)}那么，就有 P(A|B) x P(B) = P(B|A) x P(A)，即可推导出贝叶斯公式： P(A \\mid B)=\\frac{P(B \\mid A) \\times P(A)}{P(B)}{\\scriptsize }贝叶斯理论基础思想： 已知类条件概率密度参数表达式和先验概率； 利用贝叶斯公式转换成后验概率； 根据后验概率大小进行决策分类。 根据以上基本思想，可以得到贝叶斯概率计算公式表达为：后验概率 = 先验概率 × 似然概率（即新增信息所带来的调节程度）。 贝叶斯推断：广告邮件自动识别的代码实现若邮件包含某个关键词，求此邮件是广告的概率。 12345678910111213141516171819# 广告邮件数量ad_number = 4000# 正常邮件数量normal_number = 6000# 所有广告邮件中，出现 “红包” 关键词的邮件的数量ad_hongbao_number = 1000# 所有正常邮件中，出现 “红包” 关键词的邮件的数量normal_hongbao_number = 6# 广告的先验概率 P(A)P_ad = ad_number / (ad_number + normal_number)# 包含红包的先验概率 P(B)P_hongbao = (normal_hongbao_number + ad_hongbao_number) / (ad_number + normal_number)# 广告 包含红包的似然概率 P(B|A)P_hongbao_ad = ad_hongbao_number / ad_number# 求包含红包且是广告的概率 P(A|B) = P(B|A) x P(A) / P(B)P_ad_hongbao = P_hongbao_ad * P_ad / P_hongbaoprint(P_ad_hongbao) 10.9940357852882705","categories":[{"name":"算法","slug":"算法","permalink":"https://wingowen.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://wingowen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"考研","slug":"考研","date":"2022-04-21T06:19:23.000Z","updated":"2022-07-29T10:13:08.337Z","comments":true,"path":"2022/04/21/考研/","link":"","permalink":"https://wingowen.github.io/2022/04/21/%E8%80%83%E7%A0%94/","excerpt":"","text":"报考专业 深大 - 人工智能与金融科技 初试科目 101 思想政治理论 201 英语一 301 数学一 408 计算机学科专业基础综合 复试科目 FSX8 机器学习 计算机考研 408 包括（150） 数据结构 45 计算机组成原理 45 操作系统 35 计算机网络 25","categories":[{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/categories/%E8%80%83%E7%A0%94/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/tags/%E8%80%83%E7%A0%94/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"https://wingowen.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/categories/%E8%80%83%E7%A0%94/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://wingowen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/tags/%E8%80%83%E7%A0%94/"}]}