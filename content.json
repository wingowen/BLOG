{"meta":{"title":"WINGO'S BLOG","subtitle":"","description":"","author":"Wingo Wen","url":"https://wingowen.github.io","root":"/"},"pages":[{"title":"分类","date":"2022-07-29T10:17:24.000Z","updated":"2022-07-29T10:18:07.390Z","comments":true,"path":"categories/index.html","permalink":"https://wingowen.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-07-29T10:18:35.000Z","updated":"2022-07-29T10:18:54.011Z","comments":true,"path":"tags/index.html","permalink":"https://wingowen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"模型评估与选择","slug":"模型评估与选择","date":"2022-07-29T10:24:58.000Z","updated":"2022-07-29T23:58:50.538Z","comments":true,"path":"2022/07/29/模型评估与选择/","link":"","permalink":"https://wingowen.github.io/2022/07/29/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/","excerpt":"","text":"错误率和精度123456789101112131415161718import numpy as np# 真实的数据标签real_label = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1]) \\ \\ \\# 分类器的预测标签classifier_pred = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])compare_result = (real_label == classifier_pred)compare_result = compare_result.astype(np.int)# m 为样本数量 b 为预测错误样本m = len(real)b = m - np.sum(cmp)# 错误率error_rate = (b / m)*100# 精确度 accaccuracy = (1 - b / m)*100 误差模型在训练样本上的误差称为训练误差或经验误差；模型在新样本上的误差称为泛化误差。 过拟合模型：虽然训练误差接近 0，泛化误差非常大。 欠拟合的模型无论是在训练集中还是在新样本上，表现都很差，即经验误差和泛化误差都很大。 偏差和方差偏差-方差分解 bias-variance decomposition， 是解释学习算法泛化性能的一种重要工具。 偏差 bias，与真实值的偏离程度； 方差 variance，该随机变量在其期望值附近的波动程度。 评估方法评估：对学习器的泛化误差进行评估并进而做出选择。 留出法以一定比例划分训练集和测试集。 1234567891011121314151617181920212223# 导入包import numpy as npfrom sklearn.model_selection import train_test_split# 加载数据集def load_pts(): &#x27;&#x27;&#x27; return: 返回随机生成 200 个点的坐标 &#x27;&#x27;&#x27; dots = 200 # 样本数 dim = 2 # 数据维度 X = np.random.randn(dots,dim) # 建立数据集，shape(200,2) # 建立样本 X 的类别 Y = np.zeros(dots, dtype=&#x27;int&#x27;) for i in range(X.shape[0]): Y[i] = 1 return X, Y# 加载数据X,Y = load_pts()# 使用train_test_split划分训练集和测试集train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=0) 交叉验证交叉验证法 cross validation，先将数据集 D 划分为 k 个大小相似的互斥子集。 12345678910111213# 导入包from sklearn.model_selection import KFoldimport numpy as np# 生成数据集，随机生成40个点data = np.random.randn(40,2)# 交叉验证法kf = KFold(n_splits = 4, shuffle = False, random_state = None) for train, test in kf.split(data): print(train) print(test,&#x27;\\n&#x27;) 自助法有放回抽样，给定包含 m 个样本的数据集 D，我们对它进行采样产生数据集 D’ ： 每次随机从 D 中挑选一个样本； 将该样本拷贝放入 D’，然后再将该样本放回初始数据集 D 中； 重复执行 m 次该过程； 最后得到包含 m 个样本数据集 D’。 由上述表达式可知，初始数据集与自助采样数据集 D1’，自助采样数据集 D2’ 的概率分布不一样，且自助法采样的数据集正负类别比例与原始数据集不同。因此用自助法采样的数据集代替初始数据集来构建模型存在估计偏差。 123456789101112131415161718# 导入包import numpy as np# 任意设置一个数据集X = [1,4,3,23,4,6,7,8,9,45,67,89,34,54,76,98,43,52]# 通过产生的随机数获得抽取样本的序号 bootstrapping = []for i in range(len(X)): bootstrapping.append(np.random.randint(0,len(X),(1)))# 通过序号获得原始数据集中的数据D_1 = []for i in range(len(X)): print(int(bootstrapping[i])) D_1.append(X[int(bootstrapping[i])]) print(D_1) 总结 采样方法 与原始数据集的分布是否相同 相比原始数据集的容量 是否适用小数据集 是否适用大数据集 是否存在估计偏差 留出法 分层抽样 否 变小 否 是 是 交叉验证法 分层抽样 否 变小 否 是 是 自助法 放回抽样 否 不变 是 否 是 性能度量性能度量：对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量。 性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。这意味着模型的好坏是相对的，什么样的模型是好的? 这不仅取决于算法和数据，还决定于任务需求。 回归任务常用性能度量：MSE mean square error，均方差。 分类任务常用性能度量：acc accuracy，精度；错误率 二分类 - 查准率、查全率、F1对于二分类问题，可将样例根据真实值与学习器预测类别组合划分为： 真正例 true positive 假正例 false positive 真反例 true negative 假反例 false negative P(\\text { Precision })=\\frac{T P}{T P+F P} \\\\R(\\text { Recall })=\\frac{T P}{T P+F N}Recall，查全率、召回率：计算实际为正的样本中，预测正确的样本比例。 Precision，查准率：在预测为正的样本中，实际为正的概率。 P-R 曲线，BRP，Break Even Point：平衡单 P = R。 由 P-R 曲线可以看出，查全率与准确率是成反比的，这里可以理解为为了获取所有正样本而牺牲了准确性，即广撒网。BRP 还是过于简单，更常用的是 F1 度量。 F 1=\\frac{2 \\times P \\times R}{P+R}=\\frac{2 T P}{n+T P-T N}F1 的核心思想在于，在尽可能的提高 P 和 R 的同时，也希望两者之间的差异尽可能小。 当对 P 和 R 有所偏向时，则需要 F1 更泛性的度 Fβ。 F_{\\beta}=\\frac{\\left(1+\\beta^{2}\\right) \\times P \\times R}{\\left(\\beta^{2} \\times P\\right)+R}β &gt; 1时更偏向 R，β &lt; 1 更偏向 P。 如果使用了类似交叉验证法，我们会得到多个 confusion matrix： 宏观 macroF1 对于每个 confusion matrix 先计算出P、R，然后求得平均并带入公式求 macroF1； 微观 microF1 先求 confusion matrix 各元素的平均值，然后计算 P、R。 123456789101112131415161718192021222324252627282930313233343536373839404142434445import numpy as np# 加载数据集def generate_data(random_state=2021): &quot;&quot;&quot; :返回值: GT_label: 数据集的真实标签，0表示非苹果，1表示苹果 Pred_Score: 模型对数据样本预测为苹果的分数，取值范围为[0,1] &quot;&quot;&quot; noise_rate = 0.1 # 噪声比例 sample_num = 4096 # 总样本数 noise_sample_num = int(sample_num*noise_rate) # 噪声样本数 np.random.seed(random_state) Pred_Score = np.random.uniform(0,1,sample_num) GT_label = (Pred_Score&gt;0.5).astype(np.int) noise_ids = np.random.choice(a=sample_num, size=noise_sample_num, replace=False, p=None) for index in noise_ids: GT_label[index] = 1 if GT_label[index] == 0 else 0 return GT_label, Pred_ScoreGT_label, Pred_Score = generate_data()# 请你补全以下代码，计算查准率与查全率def get_PR(GT_label, Pred_Score, threshold, random_state=2021): &quot;&quot;&quot; 计算错误率和精度 :GT_label: 数据集的真实标签，0表示非苹果，1表示苹果 :Pred_Score: 模型对数据样本预测为苹果的分数，取值范围为[0,1] :threshold: 评估阈值 :random_state: 随机种子 :返回值: P: 查准率 R: 查全率 &quot;&quot;&quot; Pred_Label = list(map(lambda x: 1 if x &gt; threshold else 0, Pred_Score)) from sklearn.metrics import precision_score, recall_score P = precision_score(GT_label, Pred_Label) R = recall_score(GT_label, Pred_Label) &quot;&quot;&quot; TODO &quot;&quot;&quot; return P, R P, R = get_PR(GT_label, Pred_Score, 0.55, random_state=2021)print(&quot;查准率P ：&#123;:.2f&#125;&quot;.format(P))print(&quot;查全率R ：&#123;:.2f&#125;&quot;.format(R)) ROC 与 AUC 原理ROC 全称是受试者工作特征 Receiver Operating Characteristic) 。与 P-R 曲线不同的是，ROC使用了真正例率和假正例率。 \\begin{aligned}T P R(\\text { Precision }) &=\\frac{T P}{T P+F N} \\\\F P R(\\text { Precision }) &=\\frac{F P}{F P+T N}\\end{aligned}TPR 真正率，真正样本与实际为正的样本的比率； FPR 假正率，加正样本与实际为负的样本的比率。 若一个学习器的 ROC 曲线被另一个学习器的曲线完全包住，则可断言后者的性能优于前者； 若两 个学习器的 ROC 曲线发生交叉，则难以一般性地断言两者孰优孰劣。此时如果一定要进行比较，则较为合理的判据是比较 ROC 曲线下的面积，即 AUC Area Under ROC Curve。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import numpy as npimport matplotlib.pyplot as pltfrom sklearn.model_selection import train_test_split# 加载数据集def load_pts(): dots = 200 # 点数 X = np.random.randn(dots,2) * 15 # 建立数据集，shape(200,2)，坐标放大15倍 # 建立 X 的类别 y = np.zeros(dots, dtype=&#x27;int&#x27;) for i in range(X.shape[0]): if X[i,0] &gt; -15 and X[i,0] &lt; 15 and X[i,1] &gt; -15 and X[i,1] &lt; 15: # 矩形框内的样本都是目标类（正例） y[i] = 1 if 0 == np.random.randint(i+1) % 10: # 对数据随机地插入错误，20 个左右 y[i] = 1 - y[i] # 数据集可视化 plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 20, color = &#x27;blue&#x27;, edgecolor = &#x27;k&#x27;) plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 20, color = &#x27;red&#x27;, edgecolor = &#x27;k&#x27;) plt.xlim(-40,40) plt.ylim(-40,40) plt.grid(False) plt.tick_params( axis=&#x27;x&#x27;, which=&#x27;both&#x27;, bottom=False, top=False) return X, yX, y = load_pts()plt.show()### 训练模型 ###from sklearn.model_selection import train_test_splitfrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.svm import SVC# 将数据集拆分成训练集和测试集X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2) # 建立模型 clf1 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=4,min_samples_split=4)clf2 = GradientBoostingClassifier(max_depth=8, min_samples_leaf=10, min_samples_split=10)clf3 = SVC(kernel=&#x27;rbf&#x27;, gamma=0.001, probability=True)# 训练模型clf1.fit(X_train, y_train)clf2.fit(X_train, y_train)clf3.fit(X_train, y_train)### 评估模型 ###from sklearn.metrics import roc_curve# 模型预测y_score1 = clf1.predict_proba(X_test)y_score2 = clf2.predict_proba(X_test)y_score3 = clf3.predict_proba(X_test)# 获得 FPR、TPR 值fpr1, tpr1, _ = roc_curve(y_test, y_score1[:,1])fpr2, tpr2, _ = roc_curve(y_test, y_score2[:,1])fpr3, tpr3, _ = roc_curve(y_test, y_score3[:,1])### 绘制 ROC 曲线 ###from sklearn.metrics import aucplt.figure()# 绘制 ROC 函数def plot_roc_curve(fpr, tpr, c, name): lw = 2 roc_auc = auc(fpr,tpr) plt.plot(fpr, tpr, color=c,lw=lw, label= name +&#x27; (area = %0.2f)&#x27; % roc_auc) plt.plot([0,1], [0,1], color=&#x27;navy&#x27;, lw=lw, linestyle=&#x27;--&#x27;) plt.xlim([0, 1.0]) plt.ylim([0, 1.05]) plt.xlabel(&#x27;False Positive Rate&#x27;) plt.ylabel(&#x27;True Positive Rate&#x27;) #plt.title(&#x27;&#x27;) plt.legend(loc=&quot;lower right&quot;) plot_roc_curve(fpr1, tpr1, &#x27;red&#x27;,&#x27;DecisionTreeClassifier &#x27;) plot_roc_curve(fpr2, tpr2, &#x27;navy&#x27;,&#x27;GradientBoostingClassifier &#x27;) plot_roc_curve(fpr3, tpr3, &#x27;green&#x27;,&#x27;SVC &#x27;) plt.show() 比较检验（TODO）模型性能比较的重要因素： 实验评估得到的性能不等于泛化性能； 测试集上的性能与测试集本身的选择有很大关系； 很多机器学习算法本身有一定的随机性。 统计假设检验为我们进行学习器性能比较提供了重要依据。基于假设检验结果我们可推断出：哪个学习器更优秀，并且成立的把我有多大。 假设检验由样本推测总体的方法。 交叉验证 t 检验McNemar 检验Friedman 检验与 Nemenyi 后续检验类别不平衡在分类任务中，当不同类别的训练样本数量差别很大时，训练得到的模型往往泛化性很差 ，这就是类别不平衡。如在风控系统识别中，欺诈的样本应该是很少部分。 如果类别不平衡比例超过 4:1，那么其分类器会大大地因为数据不平衡性而无法满足分类要求的。 解决不平衡分类问题的策略可以分为两大类： 从数据层面入手 , 通过改变训练集样本分布降低不平衡程度； 从算法层面入手 , 根据算法在解决不平衡问题时的缺陷，适当地修改算法使之适应不平衡分类问题。 数据层面解决类别不平衡扩大数据样本。 重采样：通过过增加稀有类训练样本数的过采样和减少大类样本数的欠采样使不平衡的样本分布变得比较平衡 ，从而提高分类器对稀有类的识别率。 过采样：复制稀有样本； 123456789101112131415161718192021222324252627282930313233# 导入包from sklearn.datasets import make_classificationfrom collections import Counterfrom imblearn.over_sampling import RandomOverSampler# 生成样本集，用于分类算法：3 类，5000 个样本，特征维度为 2X, y = make_classification(n_samples=5000, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_classes=3, n_clusters_per_class=1, weights=[0.01, 0.05, 0.94], class_sep=0.8, random_state=0)# 打印每个类别样本数print(Counter(y))# 过采样ros = RandomOverSampler(random_state=0)X_resampled, y_resampled = ros.fit_resample(X, y)# 打印过采样后每个类别样本数print(sorted(Counter(y_resampled).items()))# 生成新的稀有样本# 导入包from imblearn.over_sampling import SMOTE# 过采样sm = SMOTE(random_state=42)X_res, y_res = sm.fit_resample(X, y)# 打印过采样后每个类别样本数print(&#x27;Resampled dataset shape %s&#x27; % Counter(y_res)) 欠采样：保存所有稀有类样本，并在丰富类别中随机选择与稀有类别样本相等数量的样本。 123456789# 导入包from imblearn.under_sampling import RandomUnderSampler# 欠采样rus = RandomUnderSampler(random_state=0)X_resampled, y_resampled = rus.fit_resample(X, y)# 打印欠采样后每个类别样本数print(sorted(Counter(y_resampled).items())) 过采样与欠采样结合：在之前的SMOTE方法中, 生成无重复的新的稀有类样本, 也很容易生成一些噪音数据。 因此, 在过采样之后需要对样本进行清洗。常见的有两种方法：SMOTETomek、SMOTEENN。 12345678# 导入包from imblearn.combine import SMOTEENN# 过采样与欠采样结合smote_enn = SMOTEENN(random_state=0)X_resampled, y_resampled = smote_enn.fit_resample(X, y)# 打印采样后每个类别样本数print(sorted(Counter(y_resampled).items())) 算法层面解决类别不平衡惩罚项方法：在大部分不平衡分类问题中，稀有类是分类的重点，在这种情况下正确识别出稀有类的样本比识别大类的样本更有价值，反过来说，错分稀有类的样本需要付出更大的代价。 通过设计一个代价函数来惩罚稀有类别的错误分类而不是分类丰富类别，可以设计出许多自然泛化为稀有类别的模型。 例如，调整 SVM 以惩罚稀有类别的错误分类。 1234567# LABEL 0 4000# LABEL 1 200# 导入相关包from sklearn.svm import SVC# 添加惩罚项clf = SVC(C=0.8, probability=True, class_weight=&#123;0:0.25, 1:0.75&#125;) 特征选择方法 样本数量分布很不平衡时，特征的分布同样也会不平衡。 大类中经常出现的特征也许在稀有类中根本不出现，这样的特征是冗余的。 选取最具有区分能力的特征，有利于提高稀有类的识别率。特征选择比较不错的方法是决策树，如 C4.5、C5.0、CART 和随机森林。","categories":[{"name":"算法","slug":"算法","permalink":"https://wingowen.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://wingowen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"贝叶斯算法","slug":"贝叶斯算法","date":"2022-07-29T10:24:58.000Z","updated":"2022-07-30T06:17:48.468Z","comments":true,"path":"2022/07/29/贝叶斯算法/","link":"","permalink":"https://wingowen.github.io/2022/07/29/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/","excerpt":"","text":"条件概率P(A|B) 表示事件 B 发生的前提下，事件 A 发生的概率： P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)}P(B|A) 表示事件 A 发生的前提下，事件 B 发生的概率： P(B \\mid A)=\\frac{P(A \\cap B)}{P(A)}那么，就有 P(A|B) x P(B) = P(B|A) x P(A)，即可推导出贝叶斯公式： P(A \\mid B)=\\frac{P(B \\mid A) \\times P(A)}{P(B)}{\\scriptsize }贝叶斯基础思想： 已知类条件概率密度参数表达式和先验概率； 利用贝叶斯公式转换成后验概率； 根据后验概率大小进行决策分类。 根据以上基本思想，可以得到贝叶斯概率计算公式表达为：后验概率 = 先验概率 × 似然概率（即新增信息所带来的调节程度）。 优点： 贝叶斯决策能对信息的价值或是否需要采集新的信息做出科学的判断； 它能对调查结果的可能性加以数量化的评价，而不是像一般的决策方法那样，对调查结果或者是完全相信,或者是完全不相信； 如果说任何调查结果都不可能完全准确，先验知识或主观概率也不是完全可以相信的，那么贝叶斯决策则巧妙地将这两种信息有机地结合起来了； 它可以在决策过程中根据具体情况下不断地使用，使决策逐步完善和更加科学。 缺点： 它需要的数据多,分析计算比较复杂,特别在解决复杂问题时,这个矛盾就更为突出； 有些数据必须使用主观概率，有些人不太相信，这也妨碍了贝叶斯决策方法的推广使用。 扩展阅读： 一文读懂概率论学习：贝叶斯理论 贝叶斯决策论&amp;朴素贝叶斯算法 朴素贝叶斯法讲解 sklearn 贝叶斯方法 贝叶斯推断：广告邮件自动识别的代码实现若邮件包含某个关键词，求此邮件是广告的概率。 12345678910111213141516171819# 广告邮件数量ad_number = 4000# 正常邮件数量normal_number = 6000# 所有广告邮件中，出现 “红包” 关键词的邮件的数量ad_hongbao_number = 1000# 所有正常邮件中，出现 “红包” 关键词的邮件的数量normal_hongbao_number = 6# 广告的先验概率 P(A)P_ad = ad_number / (ad_number + normal_number)# 包含红包的先验概率 P(B)P_hongbao = (normal_hongbao_number + ad_hongbao_number) / (ad_number + normal_number)# 广告 包含红包的似然概率 P(B|A)P_hongbao_ad = ad_hongbao_number / ad_number# 求包含红包且是广告的概率 P(A|B) = P(B|A) x P(A) / P(B)P_ad_hongbao = P_hongbao_ad * P_ad / P_hongbaoprint(P_ad_hongbao) 10.9940357852882705 极大似然估计极大似然估计方法 ，Maximum Likelihood Estimate，MLE，也称为最大概似估计或最大似然估计，是求估计的另一种方法，用部分已知数据去预测整体的分布。 极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。 通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。 极大似然估计与贝叶斯推断是统计中两种对模型的参数确定的方法，两种参数估计方法使用不同的思想。后者属于贝叶斯派，认为参数也是服从某种概率分布的，已有的数据只是在这种参数的分布下产生的；前者来自于频率派，认为参数是固定的，需要根据已经掌握的数据来估计这个参数。 极大似然估计的简单计算一个硬币被抛了100次，有61次正面朝上，计算最大似然估计。 \\begin{array}{c} \\frac{d}{d p}\\left(\\begin{array}{c} 100 \\\\ 61 \\end{array}\\right) p^{61}(1-p)^{39}=\\left(\\begin{array}{c} 100 \\\\ 61 \\end{array}\\right)\\left(61 p^{60}(1-p)^{39}-39 p^{61}(1-p)^{38}\\right) \\\\ =\\left(\\begin{array}{c} 100 \\\\ 61 \\end{array}\\right) p^{60}(1-p)^{38}(61(1-p)-39 p) \\\\ =\\left(\\begin{array}{c} 100 \\\\ 61 \\end{array}\\right) p^{60}(1-p)^{38}(61-100 p) \\\\ =0 \\end{array}当 $P = \\frac{61}{100}, 0$ 时，导数为零。因为 1 &lt; P &lt; 0，所以 $P = \\frac{61}{100}$。 极大似然估计的简单应用求极大似然估计 MLE 的一般步骤： 由总体分布导出样本的联合概率函数（或联合密度）； 把样本联合概率函数（或联合密度）中自变量看成已知常数，而把参数 $θ$ 看作自变量，得到似然函数 $l(θ)$； 求似然函数 $l(θ)$ 的最大值点，常常转化为求 $lnl(θ)$ 的最大值点，即 $θ$ 的 MLE； 在最大值点的表达式中，用样本值带入就得到参数的极大似然估计。 若随机变量 $x$ 服从一个数学期望为 $μ$、方差为 $σ^2$ 的正态分布，记为 $N(μ,σ^2)$，假设 $μ=30, σ=2$。 1234567891011import numpy as npfrom scipy.stats import normimport matplotlib.pyplot as pltμ = 30 # 数学期望σ = 2 # 方差x = μ + σ * np.random.randn(10000) # 正态分布plt.hist(x, bins=100) # 直方图显示plt.show()print(norm.fit(x)) # 返回极大似然估计，估计出参数约为 30 和 2 朴素贝叶斯分类器朴素贝叶斯分类器是一系列假设特征之间强（朴素）独立条件下以贝叶斯定理为基础的简单概率分类器，该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。 朴素贝叶斯的思想基础是：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。 对于某些类型的概率模型，在监督式学习的样本集中能获取得非常好的分类效果。在许多实际应用中，朴素贝叶斯模型参数估计使用最大似然估计方法；换而言之，在不用到贝叶斯概率或者任何贝叶斯模型的情况下，朴素贝叶斯模型也能奏效。尽管是带着这些朴素思想和过于简单化的假设，但朴素贝叶斯分类器在很多复杂的现实情形中仍能够获取相当好的效果。 MNIST 手写体数字识别123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import warningswarnings.filterwarnings(&quot;ignore&quot;)# numpy 库import numpy as np# tensorflow 库中的 mnist 数据集import tensorflow as tfmnist = tf.keras.datasets.mnist# sklearn 库中的 BernoulliNBfrom sklearn.naive_bayes import BernoulliNB# 绘图工具库 pltimport matplotlib.pyplot as pltprint(&quot;读取数据中 ...&quot;)# 载入数据(train_images, train_labels), (test_images, test_labels) = mnist.load_data()# 将 (28,28) 图像数据变形为一维的 (1,784) 位的向量train_images = train_images.reshape(len(train_images),784)test_images = test_images.reshape(len(test_images),784)print(&#x27;读取完毕!&#x27;)def plot_images(imgs): &quot;&quot;&quot;绘制几个样本图片 :param show: 是否显示绘图 :return: &quot;&quot;&quot; sample_num = min(9, len(imgs)) img_figure = plt.figure(1) img_figure.set_figwidth(5) img_figure.set_figheight(5) for index in range(0, sample_num): ax = plt.subplot(3, 3, index + 1) ax.imshow(imgs[index].reshape(28, 28), cmap=&#x27;gray&#x27;) ax.grid(False) plt.margins(0, 0) plt.show()plot_images(train_images)print(&quot;初始化并训练贝叶斯模型...&quot;)# 定义 朴素贝叶斯模型classifier_BNB = BernoulliNB()# 训练模型classifier_BNB.fit(train_images,train_labels)print(&#x27;训练完成!&#x27;)print(&quot;测试训练好的贝叶斯模型...&quot;)# 分类器在测试集上的预测值test_predict_BNB = classifier_BNB.predict(test_images)print(&quot;预测完成!&quot;)# 计算准确率accuracy = classifier_BNB.score(test_images, test_labels)print(&#x27;贝叶斯分类模型在测试集上的准确率为 :&#x27;,accuracy) 对结果进行统计比较分析。 12345678910111213141516171819202122# 记录每个类别的样本的个数，例如 &#123;0：100&#125; 即 数字为 0 的图片有 100 张 class_num = &#123;&#125;# 每个类别预测为 0-9 类别的个数，predict_num = []# 每个类别预测的准确率class_accuracy = &#123;&#125;for i in range(10): # 找到类别是 i 的下标 class_is_i_index = np.where(test_labels == i)[0] # 统计类别是 i 的个数 class_num[i] = len(class_is_i_index) # 统计类别 i 预测为 0-9 各个类别的个数 predict_num.append( [sum(test_predict_BNB[class_is_i_index] == e) for e in range(10)]) # 统计类别 i 预测的准确率 class_accuracy[i] = round(predict_num[i][i] / class_num[i], 3) * 100 print(&quot;数字 %s 的样本个数：%4s，预测正确的个数：%4s，准确率：%.4s%%&quot; % ( i, class_num[i], predict_num[i][i], class_accuracy[i])) 用热力图对结果进行分析。 123456789101112import numpy as npimport seaborn as snsimport matplotlib.pyplot as pltsns.set(rc=&#123;&#x27;figure.figsize&#x27;: (12, 8)&#125;, font_scale=1.5)sns.set_style(&#x27;whitegrid&#x27;,&#123;&#x27;font.sans-serif&#x27;:[&#x27;simhei&#x27;,&#x27;sans-serif&#x27;]&#125;) np.random.seed(0)uniform_data = predict_numax = sns.heatmap(uniform_data, cmap=&#x27;YlGnBu&#x27;, vmin=0, vmax=150)ax.set_xlabel(&#x27;真实值&#x27;)ax.set_ylabel(&#x27;预测值&#x27;)plt.show()","categories":[{"name":"算法","slug":"算法","permalink":"https://wingowen.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://wingowen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"考研","slug":"考研","date":"2022-04-21T06:19:23.000Z","updated":"2022-07-29T10:13:08.337Z","comments":true,"path":"2022/04/21/考研/","link":"","permalink":"https://wingowen.github.io/2022/04/21/%E8%80%83%E7%A0%94/","excerpt":"","text":"报考专业 深大 - 人工智能与金融科技 初试科目 101 思想政治理论 201 英语一 301 数学一 408 计算机学科专业基础综合 复试科目 FSX8 机器学习 计算机考研 408 包括（150） 数据结构 45 计算机组成原理 45 操作系统 35 计算机网络 25","categories":[{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/categories/%E8%80%83%E7%A0%94/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/tags/%E8%80%83%E7%A0%94/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"https://wingowen.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/categories/%E8%80%83%E7%A0%94/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://wingowen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"考研","slug":"考研","permalink":"https://wingowen.github.io/tags/%E8%80%83%E7%A0%94/"}]}