<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>决策树算法 | WINGO BLOG</title>
  <meta name="description" content="基本概念。">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树算法">
<meta property="og:url" content="https://wingowen.github.io/2022/07/31/%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="WINGO&#39;S BLOG">
<meta property="og:description" content="基本概念。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wingowen.github.io/img/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B.png">
<meta property="article:published_time" content="2022-07-31T02:58:15.000Z">
<meta property="article:modified_time" content="2023-01-04T07:19:42.822Z">
<meta property="article:author" content="Wingo Wen">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wingowen.github.io/img/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://wingowen.github.io/2022/07/31/%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/index.html">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="WINGO'S BLOG" type="application/atom+xml">
</head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">WINGO.WEN</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md"></h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shenzhen, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
      </ul>
      
    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>得失从缘 心无增减</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%97%A5%E5%B8%B8/">日常</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B/">编程</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%80%83%E7%A0%94/">考研</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/">运维</a><span class="category-list-count">3</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Python/" style="font-size: 13px;">Python</a> <a href="/tags/gRPC/" style="font-size: 13px;">gRPC</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 14px;">机器学习</a> <a href="/tags/%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/" style="font-size: 13px;">网站收集</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3/" style="font-size: 13px;">网络相关</a> <a href="/tags/%E8%80%83%E7%A0%94/" style="font-size: 13px;">考研</a> <a href="/tags/%E8%84%9A%E6%9C%AC%E5%91%BD%E4%BB%A4/" style="font-size: 13px;">脚本命令</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/" style="font-size: 13.5px;">计算机科学</a> <a href="/tags/%E9%83%A8%E7%BD%B2/" style="font-size: 13px;">部署</a> <a href="/tags/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/" style="font-size: 13px;">高等数学</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">一月 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">九月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">七月 2022</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">四月 2022</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


    
  </div>
</aside>

  
  
  <aside class="sidebar sidebar-toc collapse   in  " id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <nav id="toc" class="article-toc">
      <h3 class="toc-title">文章目录</h3>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text"> 决策树的基本概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><span class="toc-number">2.</span> <span class="toc-text"> 信息增益</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E6%AF%94"><span class="toc-number">3.</span> <span class="toc-text"> 信息增益比</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0"><span class="toc-number">4.</span> <span class="toc-text"> 基尼系数</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#id3"><span class="toc-number">5.</span> <span class="toc-text"> ID3</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#c45"><span class="toc-number">6.</span> <span class="toc-text"> C4.5</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E5%89%AA%E6%9E%9D"><span class="toc-number">7.</span> <span class="toc-text"> 损失函数与剪枝</span></a></li></ol>
    </nav>
  </div>
</aside>

<main class="main" role="main">
  <div class="content">
  <article id="post-算法/决策树算法" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      决策树算法
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2022/07/31/%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/" class="article-date">
	  <time datetime="2022-07-31T02:58:15.000Z" itemprop="datePublished">2022-07-31</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a>
  </span>


        

        <!-- <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2022/07/31/%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/#comments" class="article-comment-link">评论</a></span> -->
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <p>基本概念。</p>
<span id="more"></span>
<h1 id="决策树的基本概念"><a class="markdownIt-Anchor" href="#决策树的基本概念"></a> 决策树的基本概念</h1>
<p>决策树节点：</p>
<ul>
<li>叶节点表示一份类别或者一个值；</li>
<li>非叶节点表示一个属性划分。</li>
</ul>
<p>决策树的有向边代表了属性划分的不同取值：</p>
<ul>
<li>当属性是离散时，可将属性的每一个取值用一条边连接到子结点；</li>
<li>当属性是连续时，需要特殊处理。</li>
</ul>
<p>决策树是一种描述实例进行分类的树形结构。</p>
<p>对于某个样本，决策树模型将从根结点开始，对样本的某个属性进行测试，根据结果将其划分到子结点中，递归进行，直至将其划分到叶结点的类中。这个过程产生了从根结点到叶结点的一条路径，对应了一个测试序列。</p>
<p><img src="/img/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B.png" alt="img" /></p>
<p>决策树学习的目的是为了产生一根泛化能力强的决策树，其基本流程遵循了分而治之策略；决策树的学习过程本质上是从训练数据中寻找一组分类规则；决策树学习也可以看做是由训练数据集估计条件概率模型。</p>
<p>由上述描述可以得知，决策树学习是一个递归过程，有三种情况会导致递归返回：</p>
<ul>
<li>
<p>当前结点包含的所有样本属于同一类别。</p>
</li>
<li>
<p>当前属性结合为空，或所有样本在所有属性上的取值都相同：将当前结点标记为叶结点，其类别为该节点包含的样本最多的类别。</p>
</li>
<li>
<p>当前结点包含的样本基本为空：将当前结点标记为叶结点，其类别为父节点包含样本最多的类别</p>
</li>
</ul>
<p>决策树的学习结果为：树结构 + 叶节点的取值（类别）</p>
<h1 id="信息增益"><a class="markdownIt-Anchor" href="#信息增益"></a> 信息增益</h1>
<p>熵，又称信息熵，是信息论的重要概念。熵是度量样本集合纯度的指标，熵越大，样本的纯度越低。假设当前样本集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span> 中第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 类样本所占比例的为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_i(i = 1,2,...,C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mclose">)</span></span></span></span>，则 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span> 的熵定义为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><msub><mo><mi>log</mi><mo>⁡</mo></mo><mn>2</mn></msub><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">H(D)=-\sum_{i=1}^{C} p_{i} \log _{2} p_{i}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.20696799999999996em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>信息增益表示特征对于当前样本集纯度提升的程度。某属性的信息增益越大，说明使用改属性进行划分获得的纯度提升越大。因此使用信息增益进行决策树属性选择时，选择属性信息增益最大的作为当前节点。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>D</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>H</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>v</mi><mo>=</mo><mn>1</mn></mrow><mi>V</mi></munderover><mfrac><mrow><mo fence="true">∣</mo><msup><mi>D</mi><mi>v</mi></msup><mo fence="true">∣</mo></mrow><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mi>H</mi><mrow><mo fence="true">(</mo><msup><mi>D</mi><mi>v</mi></msup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">G(D, a)=H(D)-\sum_{v=1}^{V} \frac{\left|D^{v}\right|}{|D|} H\left(D^{v}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 信息增益计算</span><br><span class="line"></span><br><span class="line">def get_G(data, index, clss_idx):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    求样本集某个属性的信息增益</span><br><span class="line">    :param data: 数据集, type:pandas.DataFrame</span><br><span class="line">    :param index: 属性索引, type:int, e.g.: 1</span><br><span class="line">    :param clss_idx: 样本类别的索引, type:int, e.g.:4</span><br><span class="line">    :return: index属性的信息增益, type:float, e.g.:0.32</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    H = 0</span><br><span class="line">    for value in np.unique(data.iloc[:,clss_idx]):</span><br><span class="line">        p = np.sum(data.iloc[:,clss_idx] == value) / data.shape[0]</span><br><span class="line">        H = H - p * np.log2(p)</span><br><span class="line">    E = 0</span><br><span class="line">    for v in np.unique(data.iloc[:,index]):</span><br><span class="line">        new_data = data[data.iloc[:,index] == v]</span><br><span class="line">        # new_data 中所有样本属于同一类，由于 xlnx 在 x = 1和 x-&gt;0 是都为0，故无需计算该项</span><br><span class="line">        if np.unique(new_data.iloc[:,clss_idx]).shape[0] == 1:</span><br><span class="line">            continue</span><br><span class="line">        TE = 0</span><br><span class="line">        for value in np.unique(data.iloc[:,clss_idx]):</span><br><span class="line">            p = np.sum(new_data.iloc[:,clss_idx] == value) / new_data.shape[0]</span><br><span class="line">            TE = TE - p * np.log2(p)</span><br><span class="line">        E = E  + new_data.shape[0] / data.shape[0] * TE</span><br><span class="line">    return H - E</span><br><span class="line"></span><br><span class="line">print(&#x27;各个属性的信息增益为&#x27;)</span><br><span class="line">for i in range(len(data.columns)-1):</span><br><span class="line">     print(data.columns[i],get_G(data,i,len(data.columns)-1))</span><br></pre></td></tr></table></figure>
<h1 id="信息增益比"><a class="markdownIt-Anchor" href="#信息增益比"></a> 信息增益比</h1>
<p>以信息增益作为划分数据集的特征，会导致对可取值数目较多的属性有所偏好。为了缓解这种不良影响，采用信息增益比作为选择属性的准则。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def get_GR(data, index, clss_idx):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    求样本集某个属性的信息增益比</span><br><span class="line">    :param data: 数据集, type:pandas.DataFrame</span><br><span class="line">    :param index: 属性索引, type:int, e.g.: 1</span><br><span class="line">    :param clss_idx: 样本类别的索引, type:int, e.g.:4</span><br><span class="line">    :return: index属性的信息增益比, type:float, e.g.:0.32</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    H = 0</span><br><span class="line">    for value in np.unique(data.iloc[:,clss_idx]):</span><br><span class="line">        p = np.sum(data.iloc[:,clss_idx] == value) / data.shape[0]</span><br><span class="line">        H = H - p * np.log2(p)</span><br><span class="line">    E = 0</span><br><span class="line">    IV = 0</span><br><span class="line">    for v in np.unique(data.iloc[:,index]):</span><br><span class="line">        new_data = data[data.iloc[:,index] == v]</span><br><span class="line">        # new_data中所有样本属于同一类，由于xlnx 在x = 1和x-&gt;0是都为0，故无需计算该项</span><br><span class="line">        if np.unique(new_data.iloc[:,clss_idx]).shape[0] == 1:</span><br><span class="line">            continue</span><br><span class="line">        TE = 0</span><br><span class="line">        for value in np.unique(data.iloc[:,clss_idx]):</span><br><span class="line">            p = np.sum(new_data.iloc[:,clss_idx] == value) / new_data.shape[0]</span><br><span class="line">            TE = TE - p * np.log2(p)</span><br><span class="line">        E = E  + new_data.shape[0] / data.shape[0] * TE</span><br><span class="line">        IV = IV - new_data.shape[0] / data.shape[0] * (np.log2(new_data.shape[0] / data.shape[0]))</span><br><span class="line">    G = H - E</span><br><span class="line">    return G / IV</span><br><span class="line">print(&#x27;各个属性的信息增益比为&#x27;)</span><br><span class="line">for i in range(len(data.columns)-1):</span><br><span class="line">    print(data.columns[i],get_GR(data,i,len(data.columns)-1))</span><br></pre></td></tr></table></figure>
<h1 id="基尼系数"><a class="markdownIt-Anchor" href="#基尼系数"></a> 基尼系数</h1>
<p>纯度使用基尼指数来度量，在使用基尼系数作为指标时，应该选择基尼指数最小的属性。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def get_Gini(data, index, clss_idx):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    求样本集某个属性的基尼系数</span><br><span class="line">    :param data: 数据集, type:pandas.DataFrame</span><br><span class="line">    :param index: 属性索引, type:int, e.g.: 1</span><br><span class="line">    :param clss_idx: 样本类别的索引, type:int, e.g.:4</span><br><span class="line">    :return: index属性的基尼系数, type:float, e.g.:0.32</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    Gini = 0</span><br><span class="line"></span><br><span class="line">    for v in np.unique(data.iloc[:,index]):</span><br><span class="line">        new_data = data[data.iloc[:,index] == v]</span><br><span class="line">        Gini_v = 1</span><br><span class="line"></span><br><span class="line">        for value in np.unique(data.iloc[:,clss_idx]):</span><br><span class="line">            p = np.sum(new_data.iloc[:,clss_idx] == value) / new_data.shape[0]</span><br><span class="line">            Gini_v = Gini_v - p * p</span><br><span class="line"></span><br><span class="line">        Gini = Gini + new_data.shape[0] / data.shape[0] * Gini_v</span><br><span class="line">    return Gini</span><br><span class="line">print(&#x27;各个属性的基尼指数为&#x27;)</span><br><span class="line">for i in range(len(data.columns)-1):</span><br><span class="line">    print(data.columns[i],get_Gini(data,i,len(data.columns)-1))</span><br></pre></td></tr></table></figure>
<h1 id="id3"><a class="markdownIt-Anchor" href="#id3"></a> ID3</h1>
<p>ID3 算法的核心是在决策树各结点上使用信息增益准则选择特征：从根结点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为节点的特征，根据特征的不同取值建立子结点。递归地调用以上方法，构建决策树。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">def build_tree_id3(data, fa, ppt_list, clss_idx):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    使用 ID3 算法在 data 数据集上建立决策树</span><br><span class="line">    :param data: 数据集, type:pandas.DataFrame</span><br><span class="line">    :param fa: 父结点, type:pandas.DataFrame</span><br><span class="line">    :param ppt_list: 属性索引列表, type:list, e.g.: [0,1,2]</span><br><span class="line">    :param clss_idx: 样本类别的索引, type:int, e.g.:4</span><br><span class="line">    :return: 决策树的根结点, type:Node</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    nu = Node(data, fa, ppt_list)</span><br><span class="line"></span><br><span class="line">    if len(np.unique(data.iloc[:, clss_idx])) == 1:</span><br><span class="line">        kind = data.iloc[:, clss_idx].value_counts().keys()[0]</span><br><span class="line">        nu.set_leaf(kind)</span><br><span class="line">        return nu</span><br><span class="line"></span><br><span class="line">    if len(ppt_list) == 0:</span><br><span class="line">        kind = data.iloc[:, clss_idx].value_counts().keys()[0]</span><br><span class="line">        nu.set_leaf(kind)</span><br><span class="line">        return nu</span><br><span class="line"></span><br><span class="line">    best = -10000000</span><br><span class="line">    best_ppt = -1</span><br><span class="line">    for ppt in ppt_list:</span><br><span class="line">        G = get_G(data, ppt, clss_idx)</span><br><span class="line">        if G &gt; best:</span><br><span class="line">            best = G</span><br><span class="line">            best_ppt = ppt</span><br><span class="line"></span><br><span class="line">    new_ppt_list = np.delete(ppt_list, np.where(ppt_list == best_ppt))</span><br><span class="line"></span><br><span class="line">    for v in np.unique(data.iloc[:, best_ppt]):</span><br><span class="line">        new_data = data[data.iloc[:, best_ppt] == v]</span><br><span class="line"></span><br><span class="line">        ch_node = build_tree_id3(new_data, nu, new_ppt_list, clss_idx)</span><br><span class="line">        nu.add_child(ch_node)</span><br><span class="line"></span><br><span class="line">        if ch_node.is_leaf:</span><br><span class="line">            nu.add_leaf_ch(ch_node)</span><br><span class="line">        else :</span><br><span class="line">            for nd in ch_node.leaf_ch:</span><br><span class="line">                nu.add_leaf_ch(nd)</span><br><span class="line">    return nu</span><br><span class="line"></span><br><span class="line">ori_ppt = np.arange(len(data.columns)-1)</span><br><span class="line">root_id3 = build_tree_id3(data, None, ori_ppt, len(data.columns)-1)</span><br><span class="line"># 可视化</span><br><span class="line">createPlot(root_id3)</span><br></pre></td></tr></table></figure>
<h1 id="c45"><a class="markdownIt-Anchor" href="#c45"></a> C4.5</h1>
<p>C4.5 算法对 ID3 算法进行了改进，即使用信息增益比来选择特征，其余和 ID3 算法基本相同。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">def build_tree_c45(data, fa, ppt_list, clss_idx):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    使用C4.5算法在data数据集上建立决策树</span><br><span class="line">    :param data: 数据集, type:pandas.DataFrame</span><br><span class="line">    :param fa: 父结点, type:pandas.DataFrame</span><br><span class="line">    :param ppt_list: 属性索引列表, type:list, e.g.: [0,1,2]</span><br><span class="line">    :param clss_idx: 样本类别的索引, type:int, e.g.:4</span><br><span class="line">    :return: 决策树的根结点, type:Node</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    nu = Node(data, fa, ppt_list)</span><br><span class="line"></span><br><span class="line">    if len(np.unique(data.iloc[:, clss_idx])) == 1:</span><br><span class="line">        kind = data.iloc[:, clss_idx].value_counts().keys()[0]</span><br><span class="line">        nu.set_leaf(kind)</span><br><span class="line">        return nu</span><br><span class="line"></span><br><span class="line">    if len(ppt_list) == 0:</span><br><span class="line">        kind = data.iloc[:, clss_idx].value_counts().keys()[0]</span><br><span class="line">        nu.set_leaf(kind)</span><br><span class="line">        return nu</span><br><span class="line"></span><br><span class="line">    best = -10000000</span><br><span class="line">    best_ppt = -1</span><br><span class="line">    for ppt in ppt_list:</span><br><span class="line">        G = get_GR(data, ppt, clss_idx)</span><br><span class="line">        if G &gt; best:</span><br><span class="line">            best = G</span><br><span class="line">            best_ppt = ppt</span><br><span class="line"></span><br><span class="line">    new_ppt_list = np.delete(ppt_list, np.where(ppt_list == best_ppt))</span><br><span class="line"></span><br><span class="line">    for v in np.unique(data.iloc[:, best_ppt]):</span><br><span class="line">        new_data = data[data.iloc[:, best_ppt] == v]</span><br><span class="line"></span><br><span class="line">        ch_node = build_tree_c45(new_data, nu,new_ppt_list, clss_idx)</span><br><span class="line">        nu.add_child(ch_node)</span><br><span class="line"></span><br><span class="line">        if ch_node.is_leaf:</span><br><span class="line">            nu.add_leaf_ch(ch_node)</span><br><span class="line">        else :</span><br><span class="line">            for nd in ch_node.leaf_ch:</span><br><span class="line">                nu.add_leaf_ch(nd)</span><br><span class="line">    return nu</span><br><span class="line">ori_ppt = np.arange(len(data.columns)-1)</span><br><span class="line"># print(data)</span><br><span class="line">root_c45 = build_tree_c45(data, None ,ori_ppt, len(data.columns)-1)</span><br><span class="line">createPlot(root_c45)</span><br></pre></td></tr></table></figure>
<h1 id="损失函数与剪枝"><a class="markdownIt-Anchor" href="#损失函数与剪枝"></a> 损失函数与剪枝</h1>
<p>决策树的剪枝往往通过最小化决策树的损失函数实现。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def cal_loss(root, alpha):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    计算以root为根结点的决策树的损失值</span><br><span class="line">    :param root: 根结点, type:Node</span><br><span class="line">    :param alpha: 损失函数中定义的参数, type:float, e.g.:0.3</span><br><span class="line">    :return: 以root为根结点的决策树的损失值, type:float, e.g.:0.24</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">    loss = 0</span><br><span class="line">    for leaf in root.leaf_ch:</span><br><span class="line">        data = leaf.data</span><br><span class="line">        for v in np.unique(data.iloc[:,len(data.columns)-1]):</span><br><span class="line">            ntk = data[data.iloc[:,len(data.columns)-1] == v].shape[0]</span><br><span class="line">            loss = loss - ntk * np.log2(ntk / data.shape[0])</span><br><span class="line"></span><br><span class="line">    loss = loss + alpha * len(root.leaf_ch)</span><br><span class="line"></span><br><span class="line">    return loss</span><br><span class="line">ori_ppt = np.arange(len(data.columns)-1)</span><br><span class="line">root_c45 = build_tree_c45(data, None, ori_ppt, len(data.columns)-1)</span><br><span class="line">cal_loss(root_c45, 0.3)</span><br></pre></td></tr></table></figure>
<p>决策树生成算法递归地产生决策树，直到无法继续。这种做法会带来过拟合问题。过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类，构建过于复杂的决策树。因此，一种解决方法是考虑决策树的复杂程度，从而对决策树进行简化。对决策树进行简化的过程称为剪枝。即从决策树中裁掉一些子树或叶结点，将其根节点或父节点作为新的叶结点。</p>
<p><strong>剪枝算法的实现</strong></p>
<p>计算每个节点的经验熵。</p>
<p>递归地从树的叶结点向上回缩，若回缩后的损失值 &gt; 回缩前的损失值，则进行剪枝，父节点变为叶节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">def tree_pruning(root, leaf, alpha):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    决策树剪枝</span><br><span class="line">    :param root: 根结点, type:Node</span><br><span class="line">    :param leaf: 叶结点, type:Node</span><br><span class="line">    :param alpha: 损失函数中定义的参数, type:float, e.g.:0.3</span><br><span class="line">    :return: 剪枝后的决策树根结点, type:Node</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    new_root = copy.deepcopy(root)</span><br><span class="line">    pre_loss = cal_loss(root, alpha)</span><br><span class="line">    flag = 1</span><br><span class="line"></span><br><span class="line">    for nl in leaf.fa.leaf_ch.copy():</span><br><span class="line">        nl.can_delete = 1</span><br><span class="line"></span><br><span class="line">    new_set = set()</span><br><span class="line">    for leaf_ch in root.leaf_ch:</span><br><span class="line">        if leaf_ch.can_delete != 1:</span><br><span class="line">            new_set.add(leaf_ch)</span><br><span class="line"></span><br><span class="line">    root.leaf_ch = new_set</span><br><span class="line">    leaf.fa.set_leaf(leaf.fa.data.iloc[:,len(root.data.columns)-1].value_counts().keys()[0])</span><br><span class="line">    root.add_leaf_ch(leaf.fa)</span><br><span class="line">    after_loss = cal_loss(root, alpha)</span><br><span class="line"></span><br><span class="line">    if after_loss &gt;= pre_loss:</span><br><span class="line">        #不剪枝</span><br><span class="line">        root = new_root</span><br><span class="line">        flag = 0</span><br><span class="line">    return root, flag</span><br><span class="line">    </span><br><span class="line">ori_ppt = np.arange(len(data.columns)-1)</span><br><span class="line">root_c45 = build_tree_c45(data, None, ori_ppt, len(data.columns)-1)</span><br><span class="line"># createPlot(root_c45)</span><br><span class="line"></span><br><span class="line">#设置超参数</span><br><span class="line">alpha = 0.3</span><br><span class="line">update = 1</span><br><span class="line">while update == 1:</span><br><span class="line">    update = 0</span><br><span class="line">    for leaf in root_c45.leaf_ch.copy():</span><br><span class="line">        root_c45,flag = tree_pruning(root_c45, leaf, alpha)</span><br><span class="line">        if flag:</span><br><span class="line">            update = 1</span><br><span class="line"># root_c45</span><br><span class="line">createPlot(root_c45)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>连续值处理</p>
<p>缺失值处理</p>

      
    </div>
    <!-- <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://wingowen.github.io/2022/07/31/%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/" title="决策树算法" target="_blank" rel="external">https://wingowen.github.io/2022/07/31/算法/决策树算法/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="" target="_blank"><span class="text-dark">WINGO.WEN</span><small class="ml-1x"></small></a></h3>
        <div>一个疯子。</div>
      </div>
    </figure>
  </div>
</div>


    </div> -->
  </article>
  
    
  <section id="comments">
  	
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2022/08/01/%E7%BC%96%E7%A8%8B/Python%E7%BC%96%E7%A8%8B/" title="Python 编程"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2022/07/30/%E8%80%83%E7%A0%94/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/" title="计算机组成"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
    <li class="toggle-toc">
      <a class="toggle-btn " data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button">    <span>[&nbsp;</span><span>文章目录</span>
        <i class="text-collapsed icon icon-anchor"></i>
        <i class="text-in icon icon-close"></i>
        <span>]</span>
      </a>
    </li>
    
  </ul>
  
  
  
  <div class="bar-right">
    
  </div>
  </div>
</nav>
  


</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
    <div class="copyright">
    	
        <div class="publishby">
        	<!-- Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>. -->
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   






</body>
</html>