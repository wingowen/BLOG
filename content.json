{"meta":{"title":"WINGO'S BLOG","subtitle":"","description":"","author":"Wingo Wen","url":"https://wingowen.github.io","root":"/"},"pages":[],"posts":[{"title":"Docker","slug":"Docker","date":"2022-04-07T08:45:18.000Z","updated":"2022-04-11T05:52:34.775Z","comments":true,"path":"2022/04/07/Docker/","link":"","permalink":"https://wingowen.github.io/2022/04/07/Docker/","excerpt":"","text":"以下 docker-compose 的版本若未特殊说明，皆为 3.0。 网络12345678# 默认创 bridge 网络docker network create default_network# 查看网络内部信息docker network inspect default_network# 查看所有网络docker network ls# 移除指定的网络docker network rm default_network 1234networks: default: external: name: self-define-network 资源Docker 的容器资源限制，CPU 按百分比进行限制，使用 docker stats [container] 查看容器的 CPU 使用率，此使用率显示的是占用宿主机的百分比。 1234567# CPU 打满的脚本#!/bin/bashwhile true;do openssl speed;done 12345deploy: resources: limits: cpus: 0.1 memory: 16G 打包123docker run -d [image] /bin/bashdocker commit [container]","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://wingowen.github.io/tags/Docker/"}]},{"title":"Big Data","slug":"Big Data","date":"2022-04-06T10:23:01.000Z","updated":"2022-04-09T14:45:08.874Z","comments":true,"path":"2022/04/06/Big Data/","link":"","permalink":"https://wingowen.github.io/2022/04/06/Big%20Data/","excerpt":"","text":"Spark一个较为广泛的定义是：Spark 是一个类 Hadoop MapReduce 的通用并行框架，专为大规模数据处理而设计的快速通用的大数据引擎及轻量级的大数据处理统一平台。 发展到现在，Spark 这个词已经不仅仅只代表 Spark 了，也代表着 Spark 生态。 Spark SQL 提供 HiveQL ( Apache Hive 的 SQL 变体，Hive 查询语言 ) 与 Spark 进行交互的 API；每个数据库表被当做一个 RDD，Spark SQL 被转换为 Spark 操作。 Spark Steaming 对实时数据流进行处理和控制，允许程序能够像处理普通 RDD 数据一样处理实时数据。 MapReduce VS. Spark： MapReduce 只提供 Map 和 Reduce 两个操作，复杂的计算需要大量的 Job 才能完成；其中间结果放置在 HDFS 文件系统中，迭代计算的效率很低；适用 Batch 数据处理，对交互式、实时数据处理支持不够；开发需要写大量的底层代码。 Spark 提供了丰富的算子；中间结果存储在内存中。 由于 MapReduce 每一步操作的结果都会被存入磁盘中，故在计算出现错时可以很好的从磁盘中恢复；Spark 则需要根据 RDD 中的信息进行数据的重新计算，会耗费一定的资源。 Spark 故障恢复的两种方式： 通过数据的血缘关系再执行一遍前面的处理。 Checkpoint 将数据存储到持久化储存中。 Spark 运行方式： 在 Spark 集群中由一个节点作为 driver 端创建 SparkContext。Spark 应用程序的入口负责调度各个运算资源，协调各个 WorkerNode上 的 Executor。根据用户输入的参数会产生若干个 worker，worker 节点运行若干个 executor，一个 executor 是一个进程，运行各自的 task，每个 task 执行相同的代码段处理不同的数据。 DAG Scheduler 划分作业，依次提交 stage 对应的 taskSet 给 task 作业调度器 TaskScheduleImpl，Task 作业调度器 submite taskSet 给 driver 端的 CoarseGrainedExecutorBackend ( 与 Executor 通信的 )，CoarseGrainedExecutorBackend 接收到 task 提交 even 后，会调用 Executor 执行 task，最终 task 是在 TaskRunner 的 run 方法内运行。 Spark 根据 RDD 之间的不同点依赖关系切分成不同的阶段（Stage）；没有依赖关系的 Stage 是可以并行执行的，但是对于 job，Spark是串行执行的，如果想要并行执行 Job，可以在 Spark 程序中进行多线程编程。 在这个 DAG 图中，Spark 能够充分了解数据之间的血缘关系，这样某些任务失败后可以根据血缘关系重新执行计算获取失败了的 RDD。 宽依赖和窄依赖 窄依赖指父 RDD 的每个分区只被子 RDD 的一个分区所使用。 宽依赖指父 RDD 的每个分区可能被多个子 RDD 的分区所使用。 Spark 的资源管理架构： Master 是 Spark 的 主控节点，在实际的生产环境中会有多个 Master，只有一个 Master 处于 active 状态。 Worker 是 Spark 的工作节点，向 Master 汇报自身的资源、Executor 执行状态的改变，并接受 Master 的命令启动 Executor 或 Driver。 Driver 是应用程序的驱动程序，每个应用包括许多小任务，Driver 负责推动这些小任务的有序执行。 Executor 是 Spark 的工作进程，由 Worker 监管，负责具体任务的执行。 在 Spark 和 Yarn 两边的角色对比中：Master 和 ResourceManager 对应，Worker 和 NodeManager 对应，Driver 和 AppMaster 对应，Executor 和 Container 对应。架构相似，因此 Spark 很容易构建在 Yarn 之上。 部署模式： Local 模式：部署在同一个进程上，只有 Driver 角色。接受任务后创建 Driver 负责应用的调度执行，不涉及 Master 和 Worker； Local-Cluster 模式：部署在同一个进程上，存在 Master 和 Worker 角色，它们作为独立线程存在于这个进程内； Standalone 模式：Spark 真正的集群模式，在这个模式下 Master 和 Worker 是独立的进程； 第三方部署模式：构建于 Yarn 或 Mesos 之上，由它们提供资源管理。 Spark on YarnSpark on Yarn 对 Job 的处理过程： 客户端提交一个任务给 Yarn ResourceManager 后，AppManager 接受任务并找到一个 Container 创建 AppMaster，此时 AppMaster 上运行的是 Spark Driver。之后 AppMaster 申请 Container 并启动，Spark Driver 在 Container 上启动 Spark Executor，并调度 Spark Task 在 Spark Executor 上运行，等到所有的任务执行完毕后，向 AppManager 取消注册并释放资源。 Spark on Yarn-Client： 客户端在提交完任务之后不会将 Spark Driver 托管给 Yarn，而是在客户端运行。AppMaster 申请完 Container 之后同样也是由 Spark Driver 去启动 Spark Executor，执行任务。 YarnYarn，Yet Another Resource Negotiator，是一个工作调度集群资源管理框架。 在 Yarn 问世前，Hadoop 使用 JobTracker 进行资源管理和作业调度。存在以下瓶颈：JobTracker 同时部署多个时只有一个是处于 active 状态；应用程序相关和资源管理相关的逻辑全部放在 JobTracker 中；MapReduce 计算模型与 JobTracker 的耦合过高。 Yarn 采用 Master &#x2F; Slave 结构，整体采用双层调度架构：第一层调度是 ResourceManager 和 NodeManager。 ResourceManager 包含 Scheduler 和 AppManager 两个组件，分管资源调度和应用管理。（进行拆分，粒度比 JobTracker 更细） NodeManager 可部署在独立机器上，用于管理机器上的资源。 第二层调度指的是 NodeManager 和 Container，NodeManger 会将资源抽象成一个个 Container 并管理它们的生命周期。 Yarn 运作流程： 客户端向 ResourceManager 的 AppManager 提交应用并请求一个 AppMaster 实例； ResourceManager 找到可以运行一个 Container 的 NodeManager，并在这个 Container 中启动 AppMaster 实例； AppMaster 向 ResourceManager 注册，注册之后，客户端就可以查询 ResourceManager 获得自己 AppMaster 的详情以及直接和 App Master 交互； 接着 AppMaster 向 Resource Manager 请求资源，即 Container； 获得 Container 后，AppMaster 启动 Container，并执行 Task； Container 执行过程中会把运行进度和状态等信息发送给 AppMaster； 客户端主动和 App Master 交流应用的运行状态、进度更新等信息； 所有工作完成 App Master 向 RM 取消注册然后关闭，同时所有的 Container 也归还给系统。 从以上流程可以了解到，AppMaster 是作为 Job 的驱动角色，它驱动了 Job 任务的调度执行。在这个运作流程中，AppManager 只需要管理 AppMaster 的生命周期以及保存它的内部状态，而 AppMaster 这个角色的抽象使得每种类型的应用都可以定制自己的 AppMaster，这样其他的计算模型就可以相对容易地运行在 Yarn 集群上。 Yarn HA假如 Container 故障 Resource Manager 可以分配其他的 Container 继续执行，当运行 AppMaster 的 Container 故障后也将分配新的 Container，AppMaster 可以从 AppManager 获取信息恢复。当 NodeManager 故障的时候系统可以先把这个节点移除，在其他 NodeManager 重启再继续任务。 ResourceManager 可以启动多台，只有其中一台是 active 状态的，其他都处于待命状态。这台 active 状态的 ResourceManager 执行的时候会向 ZooKeeper 集群写入它的状态，当它故障的时候这些 RM 首先选举出另外一台正常运行的 RM 变为 active 状态，然后从 ZooKeeper 集群加载出现故障 ResourceManager 的状态。在转移的过程中它不接收新的 Job，转移完成后才接收新 Job。 资源分配方式FIFO Scheduler 如果没有配置策略的话，所有的任务都提交到一个 default 队列，根据它们的提交顺序执行。富裕资源就执行任务，若资源不富裕就等待前面的任务执行完毕后释放资源，这就是 FIFO Scheduler 先入先出的分配方式。 在 Job1 提交时占用了所有的资源，不久后 Job2 提交了，但是此时系统中已经没有资源可以分配给它了。加入 Job1 是一个大任务，那么 Job2 就只能等待一段很长的时间才能获得执行的资源。所以先入先出的分配方式存在一个问题就是大任务会占用很多资源，造成后面的小任务等待时间太长而饿死，因此一般不使用这个默认配置。 Capacity Scheduler Capacity Scheduler 是一种多租户、弹性的分配方式。每个租户一个队列，每个队列可以配置能使用的资源上限与下限（譬如 50%，达到这个上限后即使其他的资源空置着，也不可使用），通过配置可以令队列至少有资源下限配置的资源可使用。 队列 A 和队列 B 分配了相互独立的资源。Job1 提交给队列 A 执行，它只能使用队列 A 的资源。接着 Job2 提交给了队列 B 就不必等待 Job1 释放资源了。这样就可以将大任务和小任务分配在两个队列中，这两个队列的资源相互独立，就不会造成小任务饿死的情况了。 Fair Scheduler Fair Scheduler 是一种公平的分配方式，所谓的公平就是集群会尽可能地按配置的比例分配资源给队列。 Job1 提交给队列 A，它占用了集群的所有资源。接着 Job2 提交给了队列 B，这时 Job1 就需要释放它的一半的资源给队列 A 中的 Job2 使用。接着 Job3 也提交给了队列 B，这个时候 Job2 如果还未执行完毕的话也必须释放一半的资源给 Job3。这就是公平的分配方式，在队列范围内所有任务享用到的资源都是均分的。","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://wingowen.github.io/tags/Spark/"},{"name":"Yarn","slug":"Yarn","permalink":"https://wingowen.github.io/tags/Yarn/"}]},{"title":"MySQL","slug":"MySQL","date":"2022-04-06T09:07:16.000Z","updated":"2022-04-12T09:24:08.445Z","comments":true,"path":"2022/04/06/MySQL/","link":"","permalink":"https://wingowen.github.io/2022/04/06/MySQL/","excerpt":"","text":"基本使用基本概念： 数据库 database：保存有组织的数据的容器（通常是一个文件或一组文件）。 表 table：某种特定类型数据的结构化清单。 模式 schema：关于数据库和表的布局及特性的信息。 列 column：表中的一个字段。所有表都是由一个或多个列组成的。 数据类型 datatype：所容许的数据的类型。每个表列都有相应的数据类型，它限制（或容许）该列中存储的数据。 行 row：表中的一个记录。 主键 primary key：一列（或一组列），其值能够唯一区分表中每个行。 MySQL 连接信息： IP:PORT USERNAME PASSWORD (optional) 常用命令： 123456789101112131415# 库SHOW DATABASES;USE [database];# 表SHOW TABLES;SHOW COLUMNS FROM [table];= DESCRIBE [table];# SHOW 相关HELP SHOW;SHOW STATUS; # 服务器状态信息SHOW CREATE [database]; # 显示建库语句SHOW CREATE [table]; # 显示建表语句SHOW GRANTS; # 显示授予用户的安全权限SHOW ERRORS;SHOW WARNINGS; 子句 clause： SQL 语句由子句构成，有些子句是必需的，而有的是可选的。 检索数据一般检索，去重检索，范围检索； 排序检索。 SELECT1234567891011SELECT [column] FROM [table];SELECT [column01], [column02], [column03] FROM [table];SELECT * FROM [table];SELECT DISTINCT [column] FROM table; # 去重，应用于所有列SELECT [column] from table LIMIT 5; # 前五行SELECT [column] from table LIMIT 5.5; # 五行之后的五行= LIMIT 5 OFFSET 5SELECT [table].[column] FROM [database].[table]; # 完全限定 排序1234567SELECT [column] FROM [table] ORDER BY [column];SELECT [column] FROM [table] ORDER BY [column01], [column02]; # 01 相同则则按02SELECT [column] FROM [table] ORDER BY [column] DESC; # 降序SELECT [column] FROM [table] ORDER BY [column01] DESC, [column02]; # 只作用于 01SELECT [column] FROM [table] ORDER BY [column] DESC LIMIT 1; 大小写与排序： MySQL 默认为字典 dictionary 排序，A 与 a 相同。数据管理员能够在需要的时候改变这种行为。 子句位置： 在给出 ORDER BY 子句时，应该保证它位于 FROM 子句之后。如果使用 LIMIT，它必须位于ORDER BY之后。使用子句的次序不对将产生错误消息。 过滤只检索所需数据需要指定搜索条件 search criteria，搜索条件也称为过滤条件 filter condition。 MySQL 在执行匹配时默认不区分大小写。 1SELECT [column] FROM [table] WHERE a=b; 子句位置： 在同时使用 ORDER BY 和 WHERE子 句时，应该让 ORDER BY 位于 WHERE 之后，否则将会产生错误。 WHERE 子句操作符 1SELECT [column] FROM [table] between low AND high; 空值检测1SELECT [column] FROM [table] WHERE column IS NULL; NULL 与 匹配： NULL 具有特殊的含义，数据库不知道它们是否匹配，所以在匹配过滤时不返回它们。 组合 WHERE 子句操作符 operator： 用来联结或改变 WHERE 子句中的子句的关键字。也称为逻辑操作符 logical operator。 AND 操作符： 1SELECT [column] FROM [table] WHERE a=b AND c=d; OR 操作符： 1SELECT [column] FROM [table] WHERE a=b OR c=d; WHERE 可包含任意数目的 AND 和 OR 操作符。允许两者结合以进行复杂和高级的过滤。 计算次序： AND 操作符的优先级高于 OR 操作符。可使用圆括号来明确的分组相应的操作符。 1SELECT [column] FROM [table] WHERE (a=b OR c=d) AND e&gt;f; 任何时候使用具有 AND 和 OR 操作符的 WHERE 子句，都应该使用圆括号明确地分组操作符，消除歧义。 IN 操作符： 功能与 OR 相当，但更加简介与快速，并且能包含其它 SELECT 语句，动态建立 WHERE 子句。 12SELECT [column] FROM [table] a IN (b, c);= WHERE a=b OR a=c; NOT 操作符： WHERE 子句后的 NOT 只用来否定它之后跟的任何条件。 通配符通配符 wildcard，用来匹配值的一部分的特殊字符。 搜索模式 search pattern，由字面值、通配符或两者组合构成的搜索条件。 通配符本身实际是 SQL 的 WHERE 子句中有特殊含义的字符，SQL 支持几种通配符。为在搜索子句中使用通配符，必须使用 LIKE 操作符。LIKE 指示 MySQL，后跟的搜索模式利用通配符匹配而不是直接相等匹配进行比较。 LIKE 操作符： % 通配符：匹配多个字符。 1SELECT [column] FROM [table] WHERE a LIKE &#x27;%abc%&#x27;; 注意，通配符 % 匹配不了 NULL。 _ 通配符：匹配单个字符。 注意，通配符搜索的处理更费事，不要滥用。 正则表达式正则表达式的相关知识可参考：《正则表达式必知必会》 123SELECT [column] from [table] WHERE a REGEXP &#x27;1000&#x27; ORDER BY b; 正则表达式默认不区分大小写。 12REGEXP [exp];REGEXP BiNARY [exp]; # 区分大小写 MySQL 支持一小部分正则表达式，以下列出大部分： 123456&#x27;abcd&#x27; # 包含 abcd&#x27;.000&#x27; # . 表示任意字符&#x27;a|b&#x27; # or&#x27;[123] abc&#x27; = &#x27;[1|2|3] abc&#x27; # 匹配特定字符 123&#x27;[a-z]abc&#x27; # 匹配范围任意一个字符&#x27;\\\\.&#x27; # 匹配特殊字符 123456&#x27;\\\\([0-9] sticks?\\\\)&#x27; # s? 表示 s 可选result(1 stick)(2 sticks)&#x27;[[:digit:]&#123;4&#125;]&#x27; # 匹配最少四个任意数字 1&#x27;^[0-9\\\\.]&#x27; # 以数字或 . 开头的字符 可以用带文字串的 REGEXP 来测试表达式。 1SELECT &#x27;hello&#x27; REGEXP &#x27;[0-9]&#x27;; 创建计算字段","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wingowen.github.io/tags/MySQL/"}]}],"categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://wingowen.github.io/tags/Docker/"},{"name":"Spark","slug":"Spark","permalink":"https://wingowen.github.io/tags/Spark/"},{"name":"Yarn","slug":"Yarn","permalink":"https://wingowen.github.io/tags/Yarn/"},{"name":"MySQL","slug":"MySQL","permalink":"https://wingowen.github.io/tags/MySQL/"}]}